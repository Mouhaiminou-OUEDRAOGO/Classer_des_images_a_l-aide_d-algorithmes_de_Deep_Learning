{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4nt7IYrSs-a"
      },
      "source": [
        "# **Elaboration d'un modèle personnel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRJ-E4DJSpnp"
      },
      "source": [
        "## **Import des packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eILGES8mhYjk",
        "outputId": "18f7fac4-066b-48ec-a3fb-35ed7d0a8753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras>=3.2.0 (from scikeras)\n",
            "  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->scikeras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Collecting optree (from keras>=3.2.0->scikeras)\n",
            "  Downloading optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.7/347.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Installing collected packages: namex, optree, scikit-learn, keras, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.4.1 namex-0.0.8 optree-0.12.1 scikeras-0.13.0 scikit-learn-1.5.1\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikeras 0.13.0 requires keras>=3.2.0, but you have keras 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "md16yRcb5Drb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGtQhDwxS6dn"
      },
      "source": [
        "## **Téléchargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6NZlOGk_06l",
        "outputId": "0da16882-284a-4374-861b-6e17350e8f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin vers le dossier contenant toutes les images\n",
        "images_folder = '/content/drive/MyDrive/transformed_images'\n",
        "\n",
        "# Chemins vers les dossiers de sortie sans augmentation\n",
        "train_dir_no_aug = '/content/drive/MyDrive/train_no_aug'\n",
        "val_dir_no_aug = '/content/drive/MyDrive/validation_no_aug'\n",
        "test_dir_no_aug = '/content/drive/MyDrive/test_no_aug'\n",
        "\n",
        "# Chemins vers les dossiers de sortie avec augmentation\n",
        "train_dir_aug = '/content/drive/MyDrive/train_aug'\n",
        "val_dir_aug = '/content/drive/MyDrive/validation_aug'\n",
        "test_dir_aug = '/content/drive/MyDrive/test_aug'\n",
        "\n",
        "# Créer les dossiers de sortie s'ils n'existent pas\n",
        "for directory in [train_dir_no_aug, val_dir_no_aug, test_dir_no_aug, train_dir_aug, val_dir_aug, test_dir_aug]:\n",
        "    os.makedirs(directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "CzT9nwwaNyrQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLQ7Z_NgTTKR"
      },
      "source": [
        "## **Selection des races pour l'entrainement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L2Gv1Sh3-hgl"
      },
      "outputs": [],
      "source": [
        "selected_classes = ['n02106662-German_shepherd', 'n02093428-American_Staffordshire_terrier', 'n02116738-African_hunting_dog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RAjYuTFTgo9"
      },
      "source": [
        "## **Séparation des données pour l'entrainement, la validation et le test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "825C1j3o8zuX"
      },
      "outputs": [],
      "source": [
        "def split_data(class_name, files, train_dir, val_dir, test_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    np.random.shuffle(files)\n",
        "    train_split = int(train_ratio * len(files))\n",
        "    val_split = int((train_ratio + val_ratio) * len(files))\n",
        "\n",
        "    train_files = files[:train_split]\n",
        "    val_files = files[train_split:val_split]\n",
        "    test_files = files[val_split:]\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.copy(f, os.path.join(train_dir, class_name, os.path.basename(f)))\n",
        "    for f in val_files:\n",
        "        shutil.copy(f, os.path.join(val_dir, class_name, os.path.basename(f)))\n",
        "    for f in test_files:\n",
        "        shutil.copy(f, os.path.join(test_dir, class_name, os.path.basename(f)))\n",
        "\n",
        "for class_name in selected_classes:\n",
        "    class_folder = os.path.join(images_folder, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        for directory in [train_dir_no_aug, val_dir_no_aug, test_dir_no_aug, train_dir_aug, val_dir_aug, test_dir_aug]:\n",
        "            os.makedirs(os.path.join(directory, class_name), exist_ok=True)\n",
        "\n",
        "        files = [os.path.join(class_folder, f) for f in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, f))]\n",
        "        split_data(class_name, files, train_dir_no_aug, val_dir_no_aug, test_dir_no_aug)\n",
        "        split_data(class_name, files, train_dir_aug, val_dir_aug, test_dir_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXUr7eF383_V"
      },
      "outputs": [],
      "source": [
        "for class_name in selected_classes:\n",
        "    class_folder = os.path.join(images_folder, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "        files = [os.path.join(class_folder, f) for f in os.listdir(class_folder) if os.path.isfile(os.path.join(class_folder, f))]\n",
        "        split_data(class_name, files, train_dir, val_dir, test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDfCLV3nSdzS"
      },
      "source": [
        "## **Normalisation et Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNjp8ta4zh3C",
        "outputId": "5017ef20-8532-4662-d520-8a721d5d2b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1467 images belonging to 3 classes.\n",
            "Found 420 images belonging to 3 classes.\n",
            "Found 213 images belonging to 3 classes.\n",
            "Found 1467 images belonging to 3 classes.\n",
            "Found 420 images belonging to 3 classes.\n",
            "Found 213 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation pour l'entraînement\n",
        "train_datagen_aug = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Normalisation pour validation et test\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Générateurs de données pour les données avec augmentation\n",
        "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
        "    train_dir_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator_aug = val_test_datagen.flow_from_directory(\n",
        "    val_dir_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator_aug = val_test_datagen.flow_from_directory(\n",
        "    test_dir_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Générateurs de données pour les données sans augmentation\n",
        "train_datagen_no_aug = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "train_generator_no_aug = train_datagen_no_aug.flow_from_directory(\n",
        "    train_dir_no_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator_no_aug = val_test_datagen.flow_from_directory(\n",
        "    val_dir_no_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator_no_aug = val_test_datagen.flow_from_directory(\n",
        "    test_dir_no_aug,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modélisation sans Data augmentation**"
      ],
      "metadata": {
        "id": "Jy9zqyZlgS8m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJmQvMACSimQ"
      },
      "source": [
        "### **Recherche des meilleurs hyperparamètres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E1AtZnfA1JMZ",
        "outputId": "2e383655-0845-40a2-c5a7-14e1027d1480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:46 - loss: 1.1096 - accuracy: 0.4213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 57s 374ms/step - loss: 1.1096 - accuracy: 0.4213 - val_loss: 1.0322 - val_accuracy: 0.5024\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:48 - loss: 1.0752 - accuracy: 0.4110"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 56s 371ms/step - loss: 1.0752 - accuracy: 0.4110 - val_loss: 1.0361 - val_accuracy: 0.5286\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:57 - loss: 1.0717 - accuracy: 0.4492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 62s 403ms/step - loss: 1.0717 - accuracy: 0.4492 - val_loss: 0.8910 - val_accuracy: 0.6214\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:45 - loss: 1.0879 - accuracy: 0.4008"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 61s 402ms/step - loss: 1.0879 - accuracy: 0.4008 - val_loss: 1.1066 - val_accuracy: 0.3500\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 2:24 - loss: 1.0884 - accuracy: 0.4554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 75s 501ms/step - loss: 1.0884 - accuracy: 0.4554 - val_loss: 0.9689 - val_accuracy: 0.5833\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 2:13 - loss: 1.0941 - accuracy: 0.3872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 75s 490ms/step - loss: 1.0941 - accuracy: 0.3872 - val_loss: 1.0645 - val_accuracy: 0.5024\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 2:03 - loss: 1.1158 - accuracy: 0.4022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 72s 463ms/step - loss: 1.1158 - accuracy: 0.4022 - val_loss: 1.0197 - val_accuracy: 0.5262\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 2:21 - loss: 1.0906 - accuracy: 0.3776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 74s 500ms/step - loss: 1.0906 - accuracy: 0.3776 - val_loss: 1.0688 - val_accuracy: 0.4571\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 2:05 - loss: 1.1348 - accuracy: 0.3926"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 66s 438ms/step - loss: 1.1348 - accuracy: 0.3926 - val_loss: 1.0409 - val_accuracy: 0.4857\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:43 - loss: 1.0911 - accuracy: 0.4049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 54s 356ms/step - loss: 1.0911 - accuracy: 0.4049 - val_loss: 1.0737 - val_accuracy: 0.4000\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:49 - loss: 1.1578 - accuracy: 0.3797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 58s 375ms/step - loss: 1.1578 - accuracy: 0.3797 - val_loss: 1.0363 - val_accuracy: 0.4690\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 1:57 - loss: 1.1000 - accuracy: 0.3667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 61s 404ms/step - loss: 1.1000 - accuracy: 0.3667 - val_loss: 1.0825 - val_accuracy: 0.4524\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 1:47 - loss: 1.1011 - accuracy: 0.3954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 57s 375ms/step - loss: 1.1011 - accuracy: 0.3954 - val_loss: 1.0607 - val_accuracy: 0.5357\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 1:44 - loss: 1.0982 - accuracy: 0.3763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 54s 362ms/step - loss: 1.0982 - accuracy: 0.3763 - val_loss: 1.0739 - val_accuracy: 0.4048\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 1:48 - loss: 1.1104 - accuracy: 0.3981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 58s 376ms/step - loss: 1.1104 - accuracy: 0.3981 - val_loss: 1.0188 - val_accuracy: 0.5071\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            " 46/146 [========>.....................] - ETA: 1:44 - loss: 1.0971 - accuracy: 0.3463"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2920 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 55s 362ms/step - loss: 1.0971 - accuracy: 0.3463 - val_loss: 1.0888 - val_accuracy: 0.3357\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.1442 - accuracy: 0.4185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 56s 725ms/step - loss: 1.1442 - accuracy: 0.4185 - val_loss: 1.1103 - val_accuracy: 0.3452\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.0767 - accuracy: 0.4083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 56s 742ms/step - loss: 1.0767 - accuracy: 0.4083 - val_loss: 1.0666 - val_accuracy: 0.3786\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 29s - loss: 1.0622 - accuracy: 0.4840"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 57s 759ms/step - loss: 1.0622 - accuracy: 0.4840 - val_loss: 1.0428 - val_accuracy: 0.4095\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.0821 - accuracy: 0.4083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 59s 799ms/step - loss: 1.0821 - accuracy: 0.4083 - val_loss: 1.0622 - val_accuracy: 0.4905\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.1484 - accuracy: 0.4417"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 57s 766ms/step - loss: 1.1484 - accuracy: 0.4417 - val_loss: 0.9553 - val_accuracy: 0.5833\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 27s - loss: 1.0844 - accuracy: 0.3960"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 53s 706ms/step - loss: 1.0844 - accuracy: 0.3960 - val_loss: 1.0600 - val_accuracy: 0.4833\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.1797 - accuracy: 0.4070"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 55s 730ms/step - loss: 1.1797 - accuracy: 0.4070 - val_loss: 1.0732 - val_accuracy: 0.3738\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.0890 - accuracy: 0.3865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 55s 729ms/step - loss: 1.0890 - accuracy: 0.3865 - val_loss: 1.0791 - val_accuracy: 0.3857\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.1106 - accuracy: 0.3763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 56s 738ms/step - loss: 1.1106 - accuracy: 0.3763 - val_loss: 1.0435 - val_accuracy: 0.5452\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.1085 - accuracy: 0.3599"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 54s 718ms/step - loss: 1.1085 - accuracy: 0.3599 - val_loss: 1.0820 - val_accuracy: 0.4310\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.0894 - accuracy: 0.4254"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 57s 744ms/step - loss: 1.0894 - accuracy: 0.4254 - val_loss: 0.9757 - val_accuracy: 0.5286\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "46/73 [=================>............] - ETA: 28s - loss: 1.0961 - accuracy: 0.3661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 730 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 56s 750ms/step - loss: 1.0961 - accuracy: 0.3661 - val_loss: 1.0892 - val_accuracy: 0.3548\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 27s - loss: 1.1242 - accuracy: 0.3756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 55s 734ms/step - loss: 1.1242 - accuracy: 0.3756 - val_loss: 1.0240 - val_accuracy: 0.6238\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 27s - loss: 1.1038 - accuracy: 0.3579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 54s 716ms/step - loss: 1.1038 - accuracy: 0.3579 - val_loss: 1.0754 - val_accuracy: 0.4500\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 29s - loss: 1.0723 - accuracy: 0.4260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 57s 755ms/step - loss: 1.0723 - accuracy: 0.4260 - val_loss: 1.0561 - val_accuracy: 0.5095\n",
            "Entraînement avec les paramètres : {'batch_size': 20, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "46/73 [=================>............] - ETA: 27s - loss: 1.0887 - accuracy: 0.3872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 21 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 59s 791ms/step - loss: 1.0887 - accuracy: 0.3872 - val_loss: 1.0794 - val_accuracy: 0.3929\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.1697 - accuracy: 0.3993 - val_loss: 0.9409 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8249 - accuracy: 0.6408 - val_loss: 0.7837 - val_accuracy: 0.7188\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.5694 - accuracy: 0.7629 - val_loss: 0.5748 - val_accuracy: 0.7875\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.3517 - accuracy: 0.8771 - val_loss: 0.4888 - val_accuracy: 0.7969\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.2295 - accuracy: 0.9276 - val_loss: 0.4079 - val_accuracy: 0.8719\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.3678 - val_accuracy: 0.8969\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0840 - accuracy: 0.9747 - val_loss: 0.4839 - val_accuracy: 0.8719\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.4119 - val_accuracy: 0.9031\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0178 - accuracy: 0.9974 - val_loss: 0.5207 - val_accuracy: 0.9031\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9156\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 46s 1s/step - loss: 1.0879 - accuracy: 0.3819 - val_loss: 1.1084 - val_accuracy: 0.3781\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.0372 - accuracy: 0.4743 - val_loss: 0.9974 - val_accuracy: 0.5500\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 48s 1s/step - loss: 1.0228 - accuracy: 0.5074 - val_loss: 0.9927 - val_accuracy: 0.4844\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9794 - accuracy: 0.5425 - val_loss: 0.9819 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9280 - accuracy: 0.5745 - val_loss: 0.9637 - val_accuracy: 0.5281\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9302 - accuracy: 0.5789 - val_loss: 0.9561 - val_accuracy: 0.5125\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8916 - accuracy: 0.6007 - val_loss: 0.9011 - val_accuracy: 0.5938\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.8596 - accuracy: 0.6311 - val_loss: 0.9317 - val_accuracy: 0.5594\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.8313 - accuracy: 0.6347 - val_loss: 0.8280 - val_accuracy: 0.6313\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.7658 - accuracy: 0.6861 - val_loss: 0.8222 - val_accuracy: 0.6438\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 46s 1s/step - loss: 1.0959 - accuracy: 0.4175 - val_loss: 0.9834 - val_accuracy: 0.5312\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.8188 - accuracy: 0.6556 - val_loss: 0.7269 - val_accuracy: 0.6906\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.4627 - accuracy: 0.8213 - val_loss: 0.4421 - val_accuracy: 0.8469\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.2516 - accuracy: 0.9285 - val_loss: 0.2798 - val_accuracy: 0.8969\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.1208 - accuracy: 0.9590 - val_loss: 0.3404 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0891 - accuracy: 0.9740 - val_loss: 0.3812 - val_accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0344 - accuracy: 0.9939 - val_loss: 0.3155 - val_accuracy: 0.9187\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 0.3635 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.3911 - val_accuracy: 0.9187\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9094\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.0924 - accuracy: 0.3627 - val_loss: 1.0829 - val_accuracy: 0.4313\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.0676 - accuracy: 0.4473 - val_loss: 1.0600 - val_accuracy: 0.3906\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0474 - accuracy: 0.4688 - val_loss: 1.0376 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.0323 - accuracy: 0.4813 - val_loss: 1.0774 - val_accuracy: 0.3500\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9992 - accuracy: 0.5260 - val_loss: 1.0314 - val_accuracy: 0.4750\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9857 - accuracy: 0.5347 - val_loss: 0.9707 - val_accuracy: 0.5188\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9360 - accuracy: 0.5702 - val_loss: 0.9567 - val_accuracy: 0.5250\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9081 - accuracy: 0.5963 - val_loss: 0.9532 - val_accuracy: 0.5312\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.8762 - accuracy: 0.6250 - val_loss: 0.9365 - val_accuracy: 0.5625\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8416 - accuracy: 0.6408 - val_loss: 0.8698 - val_accuracy: 0.6031\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.1034 - accuracy: 0.4184 - val_loss: 0.9837 - val_accuracy: 0.4656\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8282 - accuracy: 0.6556 - val_loss: 0.7499 - val_accuracy: 0.6781\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.5626 - accuracy: 0.7960 - val_loss: 0.5682 - val_accuracy: 0.7719\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.3181 - accuracy: 0.8936 - val_loss: 0.5784 - val_accuracy: 0.8000\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1806 - accuracy: 0.9384 - val_loss: 0.3906 - val_accuracy: 0.8969\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0925 - accuracy: 0.9634 - val_loss: 0.3567 - val_accuracy: 0.8938\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0627 - accuracy: 0.9852 - val_loss: 0.4498 - val_accuracy: 0.9062\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.3424 - val_accuracy: 0.9187\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0221 - accuracy: 0.9965 - val_loss: 0.4729 - val_accuracy: 0.9031\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0556 - accuracy: 0.9843 - val_loss: 0.4339 - val_accuracy: 0.9094\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 0.3815 - val_accuracy: 0.9062\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 49s 1s/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.4871 - val_accuracy: 0.9125\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.5234 - val_accuracy: 0.9094\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.5497 - val_accuracy: 0.9312\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.6383 - val_accuracy: 0.9187\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 7.2105e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9219\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 3.1230e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9187\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 2.2029e-04 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.9250\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.7454e-04 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 1.4252e-04 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.9219\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.0817 - accuracy: 0.4220 - val_loss: 1.0613 - val_accuracy: 0.4406\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0504 - accuracy: 0.4688 - val_loss: 1.0337 - val_accuracy: 0.4969\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0014 - accuracy: 0.5434 - val_loss: 1.0872 - val_accuracy: 0.4812\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9756 - accuracy: 0.5562 - val_loss: 0.9664 - val_accuracy: 0.5219\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9330 - accuracy: 0.5728 - val_loss: 0.9502 - val_accuracy: 0.5344\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8997 - accuracy: 0.6103 - val_loss: 0.9067 - val_accuracy: 0.5625\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8734 - accuracy: 0.6068 - val_loss: 0.8794 - val_accuracy: 0.6438\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8216 - accuracy: 0.6565 - val_loss: 0.8454 - val_accuracy: 0.6281\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.7782 - accuracy: 0.6827 - val_loss: 0.7733 - val_accuracy: 0.6625\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.7328 - accuracy: 0.6992 - val_loss: 0.7645 - val_accuracy: 0.6750\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.6937 - accuracy: 0.7170 - val_loss: 0.8371 - val_accuracy: 0.6313\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.6563 - accuracy: 0.7568 - val_loss: 0.6741 - val_accuracy: 0.7594\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.5973 - accuracy: 0.7864 - val_loss: 0.5946 - val_accuracy: 0.8188\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.4998 - accuracy: 0.8344 - val_loss: 0.6350 - val_accuracy: 0.7188\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.5087 - accuracy: 0.8134 - val_loss: 0.5853 - val_accuracy: 0.7906\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.4280 - accuracy: 0.8422 - val_loss: 0.6052 - val_accuracy: 0.7719\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.3919 - accuracy: 0.8631 - val_loss: 0.5491 - val_accuracy: 0.7937\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.3377 - accuracy: 0.8849 - val_loss: 0.5123 - val_accuracy: 0.8094\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.3026 - accuracy: 0.9032 - val_loss: 0.3708 - val_accuracy: 0.8750\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.2513 - accuracy: 0.9241 - val_loss: 0.4788 - val_accuracy: 0.8250\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.0887 - accuracy: 0.4133 - val_loss: 0.9450 - val_accuracy: 0.5875\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8129 - accuracy: 0.6745 - val_loss: 0.6729 - val_accuracy: 0.7531\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.4754 - accuracy: 0.8239 - val_loss: 0.4096 - val_accuracy: 0.8562\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.2225 - accuracy: 0.9271 - val_loss: 0.5286 - val_accuracy: 0.8219\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.1346 - accuracy: 0.9494 - val_loss: 0.4918 - val_accuracy: 0.8344\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1105 - accuracy: 0.9704 - val_loss: 0.5786 - val_accuracy: 0.8500\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0942 - accuracy: 0.9791 - val_loss: 0.3406 - val_accuracy: 0.9031\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0453 - accuracy: 0.9878 - val_loss: 0.4166 - val_accuracy: 0.9062\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.3727 - val_accuracy: 0.9219\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.4062 - val_accuracy: 0.9187\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.3796 - val_accuracy: 0.9375\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.3679 - val_accuracy: 0.9125\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9375\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 8.8314e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9281\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 3.8893e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9406\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 3.3255e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9406\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 2.8636e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9344\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 2.3024e-04 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9281\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.9247e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9469\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.7397e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9344\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.0934 - accuracy: 0.3653 - val_loss: 1.0837 - val_accuracy: 0.3719\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0794 - accuracy: 0.4080 - val_loss: 1.0724 - val_accuracy: 0.4500\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.0586 - accuracy: 0.4699 - val_loss: 1.0469 - val_accuracy: 0.5250\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.0361 - accuracy: 0.4774 - val_loss: 1.0292 - val_accuracy: 0.4531\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0120 - accuracy: 0.5017 - val_loss: 0.9995 - val_accuracy: 0.5094\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.9954 - accuracy: 0.5432 - val_loss: 0.9852 - val_accuracy: 0.5500\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.9783 - accuracy: 0.5475 - val_loss: 0.9926 - val_accuracy: 0.4875\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.9526 - accuracy: 0.5754 - val_loss: 0.9578 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.9055 - accuracy: 0.6129 - val_loss: 0.9420 - val_accuracy: 0.5375\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9018 - accuracy: 0.6120 - val_loss: 0.9038 - val_accuracy: 0.5938\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.8643 - accuracy: 0.6286 - val_loss: 0.8768 - val_accuracy: 0.5906\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.8615 - accuracy: 0.6417 - val_loss: 0.9400 - val_accuracy: 0.5531\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8144 - accuracy: 0.6530 - val_loss: 0.8287 - val_accuracy: 0.6406\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.7811 - accuracy: 0.6670 - val_loss: 0.8568 - val_accuracy: 0.5906\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.7460 - accuracy: 0.6966 - val_loss: 0.9140 - val_accuracy: 0.5781\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.7206 - accuracy: 0.7083 - val_loss: 0.7939 - val_accuracy: 0.6687\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.6741 - accuracy: 0.7393 - val_loss: 0.7334 - val_accuracy: 0.7188\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.6363 - accuracy: 0.7594 - val_loss: 0.7263 - val_accuracy: 0.6906\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.5817 - accuracy: 0.7656 - val_loss: 0.6536 - val_accuracy: 0.7312\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.5465 - accuracy: 0.7864 - val_loss: 0.6465 - val_accuracy: 0.7250\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.0966 - accuracy: 0.4228 - val_loss: 0.9962 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9494 - accuracy: 0.5684 - val_loss: 0.7927 - val_accuracy: 0.6844\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.7061 - accuracy: 0.7210 - val_loss: 0.5918 - val_accuracy: 0.7531\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.5292 - accuracy: 0.8030 - val_loss: 0.4494 - val_accuracy: 0.8313\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.2998 - accuracy: 0.8967 - val_loss: 0.3106 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.2128 - accuracy: 0.9276 - val_loss: 0.3058 - val_accuracy: 0.9125\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.1839 - accuracy: 0.9332 - val_loss: 0.3505 - val_accuracy: 0.8813\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1325 - accuracy: 0.9512 - val_loss: 0.2606 - val_accuracy: 0.9156\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0980 - accuracy: 0.9686 - val_loss: 0.2770 - val_accuracy: 0.9250\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.2907 - val_accuracy: 0.9187\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 48s 1s/step - loss: 1.1129 - accuracy: 0.3609 - val_loss: 1.0801 - val_accuracy: 0.4375\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0781 - accuracy: 0.4115 - val_loss: 1.0697 - val_accuracy: 0.4250\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0609 - accuracy: 0.4438 - val_loss: 1.0444 - val_accuracy: 0.5125\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.0383 - accuracy: 0.4804 - val_loss: 1.0393 - val_accuracy: 0.5312\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0230 - accuracy: 0.5135 - val_loss: 1.0263 - val_accuracy: 0.5469\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.0006 - accuracy: 0.5092 - val_loss: 0.9806 - val_accuracy: 0.6156\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9766 - accuracy: 0.5466 - val_loss: 0.9550 - val_accuracy: 0.5938\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9591 - accuracy: 0.5588 - val_loss: 0.9272 - val_accuracy: 0.6250\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.9274 - accuracy: 0.5772 - val_loss: 0.8940 - val_accuracy: 0.6062\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.8947 - accuracy: 0.6207 - val_loss: 0.8842 - val_accuracy: 0.6562\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.1713 - accuracy: 0.3679 - val_loss: 1.0847 - val_accuracy: 0.5094\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0278 - accuracy: 0.5065 - val_loss: 0.8872 - val_accuracy: 0.6625\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.7436 - accuracy: 0.7001 - val_loss: 0.6570 - val_accuracy: 0.7000\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.5229 - accuracy: 0.8047 - val_loss: 0.4803 - val_accuracy: 0.8219\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.3315 - accuracy: 0.8823 - val_loss: 0.4250 - val_accuracy: 0.8500\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.2062 - accuracy: 0.9311 - val_loss: 0.4000 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.1497 - accuracy: 0.9503 - val_loss: 0.3749 - val_accuracy: 0.8844\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.1022 - accuracy: 0.9705 - val_loss: 0.3111 - val_accuracy: 0.9219\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0689 - accuracy: 0.9826 - val_loss: 0.3616 - val_accuracy: 0.9094\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1104 - accuracy: 0.9643 - val_loss: 0.3104 - val_accuracy: 0.9250\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 10, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0995 - accuracy: 0.3609 - val_loss: 1.0816 - val_accuracy: 0.3812\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 47s 1s/step - loss: 1.0892 - accuracy: 0.3897 - val_loss: 1.0741 - val_accuracy: 0.3656\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0686 - accuracy: 0.4534 - val_loss: 1.0534 - val_accuracy: 0.5562\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 41s 1s/step - loss: 1.0531 - accuracy: 0.4621 - val_loss: 1.0405 - val_accuracy: 0.5500\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0446 - accuracy: 0.4647 - val_loss: 1.0451 - val_accuracy: 0.4250\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0155 - accuracy: 0.4908 - val_loss: 1.0445 - val_accuracy: 0.4469\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0083 - accuracy: 0.4917 - val_loss: 0.9888 - val_accuracy: 0.5781\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9773 - accuracy: 0.5266 - val_loss: 0.9937 - val_accuracy: 0.5125\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9621 - accuracy: 0.5519 - val_loss: 0.9587 - val_accuracy: 0.5406\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.9361 - accuracy: 0.5702 - val_loss: 0.9424 - val_accuracy: 0.5500\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 1.1682 - accuracy: 0.3550 - val_loss: 1.0659 - val_accuracy: 0.3969\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.0165 - accuracy: 0.5031 - val_loss: 0.8970 - val_accuracy: 0.6656\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.8226 - accuracy: 0.6478 - val_loss: 0.6796 - val_accuracy: 0.7344\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.5404 - accuracy: 0.7934 - val_loss: 0.5411 - val_accuracy: 0.7969\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.3639 - accuracy: 0.8811 - val_loss: 0.4373 - val_accuracy: 0.8344\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.2549 - accuracy: 0.9085 - val_loss: 0.4148 - val_accuracy: 0.8344\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.1702 - accuracy: 0.9494 - val_loss: 0.2817 - val_accuracy: 0.9031\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.1493 - accuracy: 0.9477 - val_loss: 0.2567 - val_accuracy: 0.9187\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1020 - accuracy: 0.9677 - val_loss: 0.3467 - val_accuracy: 0.9187\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.1005 - accuracy: 0.9669 - val_loss: 0.2671 - val_accuracy: 0.9125\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0822 - accuracy: 0.9756 - val_loss: 0.3596 - val_accuracy: 0.9094\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.3859 - val_accuracy: 0.9062\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0411 - accuracy: 0.9834 - val_loss: 0.3921 - val_accuracy: 0.9094\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.3711 - val_accuracy: 0.9156\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 49s 1s/step - loss: 0.0111 - accuracy: 0.9991 - val_loss: 0.4613 - val_accuracy: 0.9000\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 0.4053 - val_accuracy: 0.8938\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.4292 - val_accuracy: 0.9156\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.3703 - val_accuracy: 0.9156\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.2671 - val_accuracy: 0.9375\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.3335 - val_accuracy: 0.9312\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.1048 - accuracy: 0.3862 - val_loss: 1.0812 - val_accuracy: 0.3781\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0719 - accuracy: 0.4324 - val_loss: 1.0604 - val_accuracy: 0.4406\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 1.0590 - accuracy: 0.4358 - val_loss: 1.0530 - val_accuracy: 0.4812\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0274 - accuracy: 0.4725 - val_loss: 1.0207 - val_accuracy: 0.4906\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.9994 - accuracy: 0.5109 - val_loss: 0.9953 - val_accuracy: 0.5625\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9971 - accuracy: 0.5039 - val_loss: 0.9680 - val_accuracy: 0.6062\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 40s 1s/step - loss: 0.9581 - accuracy: 0.5510 - val_loss: 0.9358 - val_accuracy: 0.6031\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9327 - accuracy: 0.5615 - val_loss: 0.9118 - val_accuracy: 0.6438\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9125 - accuracy: 0.5859 - val_loss: 0.9213 - val_accuracy: 0.6094\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.8782 - accuracy: 0.6059 - val_loss: 0.8477 - val_accuracy: 0.6187\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8327 - accuracy: 0.6267 - val_loss: 0.8301 - val_accuracy: 0.6187\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.8131 - accuracy: 0.6545 - val_loss: 0.8454 - val_accuracy: 0.6406\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.7900 - accuracy: 0.6678 - val_loss: 0.8055 - val_accuracy: 0.7063\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.7696 - accuracy: 0.6757 - val_loss: 0.7364 - val_accuracy: 0.6906\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.7220 - accuracy: 0.7109 - val_loss: 0.7653 - val_accuracy: 0.6875\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.7120 - accuracy: 0.6940 - val_loss: 0.7431 - val_accuracy: 0.6875\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.6584 - accuracy: 0.7283 - val_loss: 0.6655 - val_accuracy: 0.7188\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.6277 - accuracy: 0.7457 - val_loss: 0.6338 - val_accuracy: 0.7688\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.5630 - accuracy: 0.7890 - val_loss: 0.6429 - val_accuracy: 0.7375\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.5836 - accuracy: 0.7751 - val_loss: 0.6023 - val_accuracy: 0.7781\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 1.1197 - accuracy: 0.3496 - val_loss: 1.0677 - val_accuracy: 0.4812\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.9878 - accuracy: 0.5301 - val_loss: 0.8844 - val_accuracy: 0.5938\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.7810 - accuracy: 0.6606 - val_loss: 0.7058 - val_accuracy: 0.7312\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.5197 - accuracy: 0.8160 - val_loss: 0.5384 - val_accuracy: 0.8125\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.3223 - accuracy: 0.8849 - val_loss: 0.3919 - val_accuracy: 0.8750\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.2386 - accuracy: 0.9071 - val_loss: 0.3657 - val_accuracy: 0.8875\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1565 - accuracy: 0.9590 - val_loss: 0.3022 - val_accuracy: 0.9312\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0809 - accuracy: 0.9738 - val_loss: 0.3883 - val_accuracy: 0.8969\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0795 - accuracy: 0.9738 - val_loss: 0.2645 - val_accuracy: 0.9062\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0790 - accuracy: 0.9731 - val_loss: 0.4638 - val_accuracy: 0.8906\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0633 - accuracy: 0.9826 - val_loss: 0.4674 - val_accuracy: 0.9125\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.4317 - val_accuracy: 0.8938\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0529 - accuracy: 0.9896 - val_loss: 0.2664 - val_accuracy: 0.9125\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.4808 - val_accuracy: 0.9031\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.4353 - val_accuracy: 0.9125\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.4049 - val_accuracy: 0.9094\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.3620 - val_accuracy: 0.9250\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 50s 1s/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.5276 - val_accuracy: 0.9125\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.5389 - val_accuracy: 0.9156\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0610 - accuracy: 0.9835 - val_loss: 0.3673 - val_accuracy: 0.9219\n",
            "Entraînement avec les paramètres : {'batch_size': 40, 'dropout_rate': 0.5, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'sgd'}\n",
            "Epoch 1/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 1.0962 - accuracy: 0.3810 - val_loss: 1.0878 - val_accuracy: 0.3812\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0844 - accuracy: 0.4028 - val_loss: 1.0678 - val_accuracy: 0.5594\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 1.0662 - accuracy: 0.4490 - val_loss: 1.0489 - val_accuracy: 0.5625\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0429 - accuracy: 0.4679 - val_loss: 1.0291 - val_accuracy: 0.5750\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 40s 1s/step - loss: 1.0347 - accuracy: 0.5022 - val_loss: 1.0084 - val_accuracy: 0.5781\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 1.0022 - accuracy: 0.5266 - val_loss: 0.9972 - val_accuracy: 0.4938\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9838 - accuracy: 0.5301 - val_loss: 0.9728 - val_accuracy: 0.5437\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.9648 - accuracy: 0.5408 - val_loss: 0.9312 - val_accuracy: 0.6094\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.9348 - accuracy: 0.5728 - val_loss: 0.9383 - val_accuracy: 0.5469\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.9133 - accuracy: 0.5902 - val_loss: 0.9391 - val_accuracy: 0.5250\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8855 - accuracy: 0.6146 - val_loss: 0.8864 - val_accuracy: 0.6031\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.8731 - accuracy: 0.6155 - val_loss: 0.8740 - val_accuracy: 0.6219\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.8434 - accuracy: 0.6521 - val_loss: 0.8445 - val_accuracy: 0.6250\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8035 - accuracy: 0.6757 - val_loss: 0.9096 - val_accuracy: 0.5813\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 46s 1s/step - loss: 0.7690 - accuracy: 0.6888 - val_loss: 0.7875 - val_accuracy: 0.6438\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 52s 1s/step - loss: 0.7579 - accuracy: 0.6962 - val_loss: 0.7270 - val_accuracy: 0.7000\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 51s 1s/step - loss: 0.6937 - accuracy: 0.7179 - val_loss: 0.7391 - val_accuracy: 0.6906\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 48s 1s/step - loss: 0.6698 - accuracy: 0.7254 - val_loss: 0.6494 - val_accuracy: 0.7656\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.6132 - accuracy: 0.7568 - val_loss: 0.6758 - val_accuracy: 0.7250\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.5704 - accuracy: 0.7716 - val_loss: 0.5842 - val_accuracy: 0.7906\n",
            "Meilleurs Hyperparamètres : {'batch_size': 40, 'dropout_rate': 0.0, 'epochs': 20, 'init_mode': 'he_normal', 'optimizer': 'adam'}\n",
            "Meilleure Précision de Validation : 0.9468749761581421\n"
          ]
        }
      ],
      "source": [
        "def create_model(optimizer='adam', init_mode='uniform', dropout_rate=0.0):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_initializer=init_mode),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "param_grid = {\n",
        "    'batch_size': [10, 20, 40],\n",
        "    'epochs': [10, 20],\n",
        "    'optimizer': ['adam', 'sgd'],\n",
        "    'init_mode': ['uniform', 'he_normal'],\n",
        "    'dropout_rate': [0.0, 0.5]\n",
        "}\n",
        "\n",
        "# Convertir le param_grid en liste de dictionnaires\n",
        "param_list = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Initialiser les meilleures performances et paramètres\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "\n",
        "# Boucle pour rechercher les meilleurs hyperparamètres\n",
        "for params in param_list:\n",
        "    print(f\"Entraînement avec les paramètres : {params}\")\n",
        "\n",
        "    # Créer le modèle avec les hyperparamètres actuels\n",
        "    model = create_model(optimizer=params['optimizer'], init_mode=params['init_mode'], dropout_rate=params['dropout_rate'])\n",
        "\n",
        "    # Entraîner le modèle\n",
        "    history = model.fit(\n",
        "        train_generator_no_aug,\n",
        "        steps_per_epoch=train_generator_no_aug.samples // params['batch_size'],\n",
        "        epochs=params['epochs'],\n",
        "        validation_data=val_generator_no_aug,\n",
        "        validation_steps=val_generator_no_aug.samples // params['batch_size'],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Obtenir les meilleures performances de validation\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "    # Mettre à jour les meilleures performances et paramètres si nécessaire\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Meilleurs Hyperparamètres : {best_params}\")\n",
        "print(f\"Meilleure Précision de Validation : {best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DMaUs3CSuwJ"
      },
      "source": [
        "### **Entraînement du modèle avec les meilleurs hyperparamètres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piIP-RZ81I-e",
        "outputId": "1df7a931-a9b4-427d-ce07-7e232a26e134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.1134 - accuracy: 0.4446 - val_loss: 0.9556 - val_accuracy: 0.5156\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.8158 - accuracy: 0.6530 - val_loss: 0.7399 - val_accuracy: 0.6906\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 0.5001 - accuracy: 0.8152 - val_loss: 0.5994 - val_accuracy: 0.7656\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.3016 - accuracy: 0.8884 - val_loss: 0.3897 - val_accuracy: 0.8875\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.1553 - accuracy: 0.9512 - val_loss: 0.3577 - val_accuracy: 0.8969\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 45s 1s/step - loss: 0.1075 - accuracy: 0.9695 - val_loss: 0.4333 - val_accuracy: 0.8844\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 0.0684 - accuracy: 0.9843 - val_loss: 0.3806 - val_accuracy: 0.9094\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 47s 1s/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.4034 - val_accuracy: 0.9125\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.5371 - val_accuracy: 0.8969\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4357 - val_accuracy: 0.9312\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.5251 - val_accuracy: 0.9000\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5846 - val_accuracy: 0.9062\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 42s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5277 - val_accuracy: 0.9187\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 43s 1s/step - loss: 5.3920e-04 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9156\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 4.2483e-04 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.9125\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 41s 1s/step - loss: 3.8856e-04 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.9125\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 2.7550e-04 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.9250\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 2.4874e-04 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9125\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 2.0516e-04 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 44s 1s/step - loss: 1.8471e-04 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 0.9250\n"
          ]
        }
      ],
      "source": [
        "model = create_model(optimizer=best_params['optimizer'], init_mode=best_params['init_mode'], dropout_rate=best_params['dropout_rate'])\n",
        "history = model.fit(\n",
        "    train_generator_no_aug,\n",
        "    steps_per_epoch=train_generator_no_aug.samples // best_params['batch_size'],\n",
        "    epochs=best_params['epochs'],\n",
        "    validation_data=val_generator_no_aug,\n",
        "    validation_steps=val_generator_no_aug.samples // best_params['batch_size'],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3DmfvusS5lh"
      },
      "source": [
        "### **Evaluation du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-ZME-g61X-o",
        "outputId": "1f2ea074-5878-4f81-bca9-5d1a06833b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 2s 294ms/step\n",
            "7/7 - 2s - loss: 0.1998 - accuracy: 0.9531 - 2s/epoch - 312ms/step\n",
            "Précision sur les données de test : 95.31%\n"
          ]
        }
      ],
      "source": [
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(test_generator_no_aug)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator_no_aug.classes\n",
        "\n",
        "# Évaluation du modèle sur les données de test\n",
        "test_loss, test_accuracy = model.evaluate(test_generator_no_aug, verbose=2)\n",
        "\n",
        "# Afficher la précision du modèle sur les données de test\n",
        "print(f'Précision sur les données de test : {test_accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkMVa1YE1IRp"
      },
      "source": [
        "\n",
        "\n",
        "## **Modélisation avec Data augmentation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQgeLUt2VJGy"
      },
      "source": [
        "### **Recherche des meilleurs hyperparamètres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P65jUR2DXA7Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "1ff7ef0d-51bc-44c8-bf2d-419b4fd55c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'adam'}\n",
            "Epoch 1/10\n",
            " 46/146 [========>.....................] - ETA: 2:00 - loss: 1.2083 - accuracy: 0.3817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1460 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 42 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146/146 [==============================] - 63s 414ms/step - loss: 1.2083 - accuracy: 0.3817 - val_loss: 1.0510 - val_accuracy: 0.4667\n",
            "Entraînement avec les paramètres : {'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init_mode': 'uniform', 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            " 30/146 [=====>........................] - ETA: 2:13 - loss: 1.1049 - accuracy: 0.3602"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-80a99f6d0452>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Entraîner le modèle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mtrain_generator_aug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator_aug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def create_model(optimizer='adam', init_mode='uniform', dropout_rate=0.0):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_initializer=init_mode),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "param_grid = {\n",
        "    'batch_size': [10, 20, 40],\n",
        "    'epochs': [10, 20],\n",
        "    'optimizer': ['adam', 'sgd'],\n",
        "    'init_mode': ['uniform', 'he_normal'],\n",
        "    'dropout_rate': [0.0, 0.5]\n",
        "}\n",
        "\n",
        "# Convertir le param_grid en liste de dictionnaires\n",
        "param_list = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Initialiser les meilleures performances et paramètres\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "\n",
        "# Boucle pour rechercher les meilleurs hyperparamètres\n",
        "for params in param_list:\n",
        "    print(f\"Entraînement avec les paramètres : {params}\")\n",
        "\n",
        "    # Créer le modèle avec les hyperparamètres actuels\n",
        "    model = create_model(optimizer=params['optimizer'], init_mode=params['init_mode'], dropout_rate=params['dropout_rate'])\n",
        "\n",
        "    # Entraîner le modèle\n",
        "    history = model.fit(\n",
        "        train_generator_aug,\n",
        "        steps_per_epoch=train_generator_aug.samples // params['batch_size'],\n",
        "        epochs=params['epochs'],\n",
        "        validation_data=val_generator_aug,\n",
        "        validation_steps=val_generator_aug.samples // params['batch_size'],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Obtenir les meilleures performances de validation\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "    # Mettre à jour les meilleures performances et paramètres si nécessaire\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Meilleurs Hyperparamètres : {best_params}\")\n",
        "print(f\"Meilleure Précision de Validation : {best_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_UNm3l2Tc5y"
      },
      "source": [
        "### **Entraînement du modèle avec les meilleurs hyperparamètres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlGh4E9rRPKn"
      },
      "outputs": [],
      "source": [
        "model_aug = create_model(optimizer=best_params['optimizer'], init_mode=best_params['init_mode'], dropout_rate=best_params['dropout_rate'])\n",
        "history = model.fit(\n",
        "    train_generator_aug,\n",
        "    steps_per_epoch=train_generator_aug.samples // best_params['batch_size'],\n",
        "    epochs=best_params['epochs'],\n",
        "    validation_data=val_generator_aug,\n",
        "    validation_steps=val_generator_aug.samples // best_params['batch_size'],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LWhLHLXVcHX"
      },
      "source": [
        "## **Evaluation du modèle avec Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfH3wYRd5lHE"
      },
      "outputs": [],
      "source": [
        "# Prédictions sur l'ensemble de test\n",
        "y_pred = model.predict(test_generator_aug)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator_aug.classes\n",
        "\n",
        "# Évaluation du modèle sur les données de test\n",
        "test_loss, test_accuracy = model.evaluate(test_generator_aug, verbose=2)\n",
        "\n",
        "# Afficher la précision du modèle sur les données de test\n",
        "print(f'Précision sur les données de test : {test_accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMcrovTlWjRy"
      },
      "source": [
        "## **Affichage de la matrice de confusion du meilleur modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNW61LWO5rK-"
      },
      "outputs": [],
      "source": [
        "# Matrice de confusion\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=test_generator_aug.class_indices.keys())\n",
        "cm_display.plot(xticks_rotation='vertical')\n",
        "plt.title('Matrice de confusion')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}